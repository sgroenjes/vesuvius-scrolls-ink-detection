{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## summary\n\n* 2.5d segmentation\n    *  segmentation_models_pytorch \n    *  Unet\n* use only 6 slices\n* slide inference","metadata":{}},{"cell_type":"code","source":"\nfrom sklearn.metrics import roc_auc_score, accuracy_score, f1_score, log_loss, fbeta_score\nimport pickle\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.cuda.amp import autocast, GradScaler\nimport warnings\nimport sys\nimport pandas as pd\nimport os\nimport gc\nimport sys\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\nimport cv2\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport argparse\nimport importlib\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.optim.lr_scheduler import _LRScheduler\n\nimport datetime\nimport wandb\n\nimport numpy as np\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\nimport segmentation_models_pytorch as smp","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:51:15.41084Z","iopub.execute_input":"2023-04-04T04:51:15.411176Z","iopub.status.idle":"2023-04-04T04:51:20.141027Z","shell.execute_reply.started":"2023-04-04T04:51:15.411146Z","shell.execute_reply":"2023-04-04T04:51:20.13956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sys.path.append('/kaggle/input/pretrainedmodels/pretrainedmodels-0.7.4')\nsys.path.append('/kaggle/input/efficientnet-pytorch/EfficientNet-PyTorch-master')\nsys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\nsys.path.append('/kaggle/input/segmentation-models-pytorch/segmentation_models.pytorch-master')","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:51:20.143786Z","iopub.execute_input":"2023-04-04T04:51:20.144176Z","iopub.status.idle":"2023-04-04T04:51:22.838683Z","shell.execute_reply.started":"2023-04-04T04:51:20.144135Z","shell.execute_reply":"2023-04-04T04:51:22.837613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## config","metadata":{}},{"cell_type":"code","source":"class CFG:\n    # ============== comp exp name =============\n    comp_name = 'vesuvius'\n\n    # comp_dir_path = './'\n    comp_dir_path = '/kaggle/input/'\n    comp_folder_name = 'vesuvius-challenge-ink-detection'\n    # comp_dataset_path = f'{comp_dir_path}datasets/{comp_folder_name}/'\n    comp_dataset_path = f'{comp_dir_path}{comp_folder_name}/'\n    \n    exp_name = 'vesuvius_2d_slide_exp002'\n\n    # ============== pred target =============\n    target_size = 1\n\n    # ============== model cfg =============\n    model_name = 'Unet'\n#     backbone = 'efficientnet-b4'\n    backbone = 'se_resnext50_32x4d'\n\n    in_chans = 6 # 65\n    # ============== training cfg =============\n    size = 224\n    tile_size = 224\n    stride = tile_size // 8\n\n    batch_size = 16 # 32\n    use_amp = True\n\n    scheduler = 'GradualWarmupSchedulerV2'\n    # scheduler = 'CosineAnnealingLR'\n    epochs = 15\n\n    warmup_factor = 10\n    lr = 1e-4 / warmup_factor\n\n    # ============== fold =============\n    valid_id = 2\n\n    objective_cv = 'binary'  # 'binary', 'multiclass', 'regression'\n    metric_direction = 'maximize'  # maximize, 'minimize'\n    # metrics = 'dice_coef'\n\n    # ============== fixed =============\n    pretrained = True\n    inf_weight = 'best'  # 'best'\n\n    min_lr = 1e-6\n    weight_decay = 1e-6\n    max_grad_norm = 1000\n\n    print_freq = 50\n    num_workers = 4\n\n    seed = 42\n\n    # ============== augmentation =============\n    train_aug_list = [\n        # A.RandomResizedCrop(\n        #     size, size, scale=(0.85, 1.0)),\n        A.Resize(size, size),\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.5),\n        A.RandomBrightnessContrast(p=0.75),\n        A.ShiftScaleRotate(p=0.75),\n        A.OneOf([\n                A.GaussNoise(var_limit=[10, 50]),\n                A.GaussianBlur(),\n                A.MotionBlur(),\n                ], p=0.4),\n        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n        A.CoarseDropout(max_holes=1, max_width=int(size * 0.3), max_height=int(size * 0.3), \n                        mask_fill_value=0, p=0.5),\n        # A.Cutout(max_h_size=int(size * 0.6),\n        #          max_w_size=int(size * 0.6), num_holes=1, p=1.0),\n        A.Normalize(\n            mean= [0] * in_chans,\n            std= [1] * in_chans\n        ),\n        ToTensorV2(transpose_mask=True),\n    ]\n\n    valid_aug_list = [\n        A.Resize(size, size),\n        A.Normalize(\n            mean= [0] * in_chans,\n            std= [1] * in_chans\n        ),\n        ToTensorV2(transpose_mask=True),\n    ]\n","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:51:23.62525Z","iopub.execute_input":"2023-04-04T04:51:23.625553Z","iopub.status.idle":"2023-04-04T04:51:23.638088Z","shell.execute_reply.started":"2023-04-04T04:51:23.625523Z","shell.execute_reply":"2023-04-04T04:51:23.636525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IS_DEBUG = False\nmode = 'train' if IS_DEBUG else 'test'\nTH = 0.40","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:51:23.639547Z","iopub.execute_input":"2023-04-04T04:51:23.640341Z","iopub.status.idle":"2023-04-04T04:51:23.656451Z","shell.execute_reply.started":"2023-04-04T04:51:23.640303Z","shell.execute_reply":"2023-04-04T04:51:23.655252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:51:23.658119Z","iopub.execute_input":"2023-04-04T04:51:23.65855Z","iopub.status.idle":"2023-04-04T04:51:23.811369Z","shell.execute_reply.started":"2023-04-04T04:51:23.658495Z","shell.execute_reply":"2023-04-04T04:51:23.810212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## helper","metadata":{}},{"cell_type":"code","source":"# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\ndef rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    # pixels = (pixels >= thr).astype(int)\n    \n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:51:23.813141Z","iopub.execute_input":"2023-04-04T04:51:23.813569Z","iopub.status.idle":"2023-04-04T04:51:23.824293Z","shell.execute_reply.started":"2023-04-04T04:51:23.813471Z","shell.execute_reply":"2023-04-04T04:51:23.823167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## dataset","metadata":{}},{"cell_type":"code","source":"def read_image(fragment_id, mode):\n    images = []\n\n    # idxs = range(65)\n    mid = 65 // 2\n    start = mid - CFG.in_chans // 2\n    end = mid + CFG.in_chans // 2\n    idxs = range(start, end)\n\n    for i in tqdm(idxs):\n        \n        image = cv2.imread(CFG.comp_dataset_path + f\"{mode}/{fragment_id}/surface_volume/{i:02}.tif\", 0)\n\n        pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n        pad1 = (CFG.tile_size - image.shape[1] % CFG.tile_size)\n\n        image = np.pad(image, [(0, pad0), (0, pad1)], constant_values=0)\n\n        images.append(image)\n    images = np.stack(images, axis=2)\n    \n    return images","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:51:23.826048Z","iopub.execute_input":"2023-04-04T04:51:23.826492Z","iopub.status.idle":"2023-04-04T04:51:23.835717Z","shell.execute_reply.started":"2023-04-04T04:51:23.826453Z","shell.execute_reply":"2023-04-04T04:51:23.834666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_transforms(data, cfg):\n    if data == 'train':\n        aug = A.Compose(cfg.train_aug_list)\n    elif data == 'valid':\n        aug = A.Compose(cfg.valid_aug_list)\n\n    # print(aug)\n    return aug\n\nclass CustomDataset(Dataset):\n    def __init__(self, images, cfg, labels=None, transform=None, pseudo_label=False):\n        self.images = images\n        self.cfg = cfg\n        self.labels = labels\n        self.transform = transform\n        self.pseudo_label = pseudo_label\n\n    def __len__(self):\n        # return len(self.xyxys)\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        # x1, y1, x2, y2 = self.xyxys[idx]\n        image = self.images[idx]\n        \n        if self.labels is not None:\n            label = self.labels[idx]\n\n            if self.transform:\n                data = self.transform(image=image, mask=label)\n                image = data['image']\n                label = data['mask']\n\n            return image, label\n\n        else:\n            if self.transform:\n                data = self.transform(image=image)\n                image = data['image']\n\n            return image\n","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:51:23.838014Z","iopub.execute_input":"2023-04-04T04:51:23.839479Z","iopub.status.idle":"2023-04-04T04:51:23.848571Z","shell.execute_reply.started":"2023-04-04T04:51:23.83945Z","shell.execute_reply":"2023-04-04T04:51:23.847638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_test_dataset(fragment_id):\n    test_images = read_image(fragment_id, mode='test')  # Replace 'test' with the correct mode if needed\n    \n    x1_list = list(range(0, test_images.shape[1]-CFG.tile_size+1, CFG.stride))\n    y1_list = list(range(0, test_images.shape[0]-CFG.tile_size+1, CFG.stride))\n    \n    test_images_list = []\n    xyxys = []\n    for y1 in y1_list:\n        for x1 in x1_list:\n            y2 = y1 + CFG.tile_size\n            x2 = x1 + CFG.tile_size\n            \n            test_images_list.append(test_images[y1:y2, x1:x2])\n            xyxys.append((x1, y1, x2, y2))\n    xyxys = np.stack(xyxys)\n            \n    test_dataset = CustomDataset(test_images_list, CFG, transform=get_transforms(data='valid', cfg=CFG))\n    \n    test_loader = DataLoader(test_dataset,\n                          batch_size=CFG.batch_size,\n                          shuffle=False,\n                          num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n    \n    return test_loader, xyxys","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:51:23.85342Z","iopub.execute_input":"2023-04-04T04:51:23.854214Z","iopub.status.idle":"2023-04-04T04:51:23.863163Z","shell.execute_reply.started":"2023-04-04T04:51:23.854184Z","shell.execute_reply":"2023-04-04T04:51:23.862015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fbeta_numpy(targets, preds, beta=0.5, smooth=1e-5):\n    \"\"\"\n    https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/397288\n    \"\"\"\n    y_true_count = targets.sum()\n    ctp = preds[targets==1].sum()\n    cfp = preds[targets==0].sum()\n    beta_squared = beta * beta\n\n    c_precision = ctp / (ctp + cfp + smooth)\n    c_recall = ctp / (y_true_count + smooth)\n    dice = (1 + beta_squared) * (c_precision * c_recall) / (beta_squared * c_precision + c_recall + smooth)\n\n    return dice\n\ndef calc_fbeta(mask, mask_pred):\n    mask = mask.astype(int).flatten()\n    mask_pred = mask_pred.flatten()\n\n    best_th = 0\n    best_dice = 0\n    for th in np.array(range(10, 50+1, 5)) / 100:\n        \n        # dice = fbeta_score(mask, (mask_pred >= th).astype(int), beta=0.5)\n        dice = fbeta_numpy(mask, (mask_pred >= th).astype(int), beta=0.5)\n        print(f'th: {th}, fbeta: {dice}')\n\n        if dice > best_dice:\n            best_dice = dice\n            best_th = th\n    \n    Logger.info(f'best_th: {best_th}, fbeta: {best_dice}')\n    return best_dice, best_th\n\n\ndef calc_cv(mask_gt, mask_pred):\n    best_dice, best_th = calc_fbeta(mask_gt, mask_pred)\n\n    return best_dice, best_th","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## model","metadata":{}},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, cfg, weight=None):\n        super().__init__()\n        self.cfg = cfg\n\n        self.encoder = smp.Unet(\n            encoder_name=cfg.backbone, \n            encoder_weights=weight,\n            in_channels=cfg.in_chans,\n            classes=cfg.target_size,\n            activation=None,\n        )\n\n    def forward(self, image):\n        output = self.encoder(image)\n        output = output.squeeze(-1)\n        return output\n\ndef build_model(cfg, weight=\"imagenet\"):\n    print('model_name', cfg.model_name)\n    print('backbone', cfg.backbone)\n\n    model = CustomModel(cfg, weight)\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:51:23.864743Z","iopub.execute_input":"2023-04-04T04:51:23.865123Z","iopub.status.idle":"2023-04-04T04:51:23.87814Z","shell.execute_reply.started":"2023-04-04T04:51:23.86506Z","shell.execute_reply":"2023-04-04T04:51:23.877181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EnsembleModel:\n    def __init__(self, use_tta=False):\n        self.models = []\n        self.use_tta = use_tta\n        self.optimizers = []\n\n    def __call__(self, x):\n        outputs = [torch.sigmoid(model(x)).to('cpu').numpy()\n                   for model in self.models]\n        avg_preds = np.mean(outputs, axis=0)\n        return avg_preds\n\n    def add_model(self, model):\n        self.models.append(model)\n\n    def add_optimizer(self, optimizer):\n        self.optimizers.append(optimizer)\n\ndef build_ensemble_model():\n    ensemble = EnsembleModel()\n    for fold in [1, 2, 3]:\n        _model = build_model(CFG, weight=None)\n        _model.to(device)\n\n        model_path = f'/kaggle/input/vesuvius-models-public/{CFG.exp_name}/vesuvius-models/Unet_fold{fold}_best.pth'\n        state = torch.load(model_path)['model']\n        _model.load_state_dict(state)\n        _model.eval()\n\n        optimizer = AdamW(_model.parameters(), lr=CFG.lr)\n        ensemble.add_optimizer(optimizer)\n        ensemble.add_model(_model)\n\n    return ensemble","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:51:23.88138Z","iopub.execute_input":"2023-04-04T04:51:23.881751Z","iopub.status.idle":"2023-04-04T04:51:23.891133Z","shell.execute_reply.started":"2023-04-04T04:51:23.881723Z","shell.execute_reply":"2023-04-04T04:51:23.890126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if mode == 'test':\n    fragment_ids = sorted(os.listdir(CFG.comp_dataset_path + mode))\nelse:\n    fragment_ids = [3]","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:51:23.892497Z","iopub.execute_input":"2023-04-04T04:51:23.892968Z","iopub.status.idle":"2023-04-04T04:51:23.908Z","shell.execute_reply.started":"2023-04-04T04:51:23.892927Z","shell.execute_reply":"2023-04-04T04:51:23.906772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"train, val","metadata":{}},{"cell_type":"code","source":"def train_fn(train_loader, model, criterion, optimizer, device):\n    model.train()\n\n    scaler = GradScaler(enabled=CFG.use_amp)\n    losses = AverageMeter()\n\n    for step, (images, labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n        images = images.to(device)\n        if train_loader.dataset.pseudo_label:\n            with torch.no_grad():\n                labels = torch.sigmoid(model(images))\n        else:\n            labels = labels.to(device)\n        batch_size = labels.size(0)\n\n        with autocast(CFG.use_amp):\n            y_preds = model(images)\n            loss = criterion(y_preds, labels)\n\n        losses.update(loss.item(), batch_size)\n        scaler.scale(loss).backward()\n\n        grad_norm = torch.nn.utils.clip_grad_norm_(\n            model.parameters(), CFG.max_grad_norm)\n\n        scaler.step(optimizer)\n        scaler.update()\n        optimizer.zero_grad()\n\n    return losses.avg\n\ndef valid_fn(valid_loader, model, criterion, device, valid_xyxys, valid_mask_gt):\n    mask_pred = np.zeros(valid_mask_gt.shape)\n    mask_count = np.zeros(valid_mask_gt.shape)\n\n    model.eval()\n    losses = AverageMeter()\n\n    for step, (images, labels) in tqdm(enumerate(valid_loader), total=len(valid_loader)):\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n\n        with torch.no_grad():\n            y_preds = model(images)\n            loss = criterion(y_preds, labels)\n        losses.update(loss.item(), batch_size)\n\n        # make whole mask\n        y_preds = torch.sigmoid(y_preds).to('cpu').numpy()\n        start_idx = step*CFG.valid_batch_size\n        end_idx = start_idx + batch_size\n        for i, (x1, y1, x2, y2) in enumerate(valid_xyxys[start_idx:end_idx]):\n            mask_pred[y1:y2, x1:x2] += y_preds[i].squeeze(0)\n            mask_count[y1:y2, x1:x2] += np.ones((CFG.tile_size, CFG.tile_size))\n\n    print(f'mask_count_min: {mask_count.min()}')\n    mask_pred /= mask_count\n    return losses.avg, mask_pred\n\ndef run_inference(ensemble, test_loader):\n    for model in ensemble.models:\n        model.eval()\n    \n    mask_preds = []\n\n    for images in test_loader:\n        images = images.to(device)\n        with torch.no_grad():\n            preds = ensemble(images)\n        mask_preds.extend(preds)\n    \n    mask_preds = np.array(mask_preds)\n    return mask_preds\n\n\n\ndef postprocess_mask(mask_pred, threshold=0.5, ori_h=None, ori_w=None):\n    mask_pred = (mask_pred >= threshold).astype(int)\n    \n    if ori_h is not None and ori_w is not None:\n        resized_mask_pred = []\n        for mask in mask_pred:\n            resized_mask = cv2.resize(mask, (ori_w, ori_h), interpolation=cv2.INTER_NEAREST)\n            resized_mask_pred.append(resized_mask)\n        mask_pred = np.array(resized_mask_pred)\n    \n    return mask_pred","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GradualWarmupScheduler(_LRScheduler):\n    \"\"\"Gradually warm-up(increasing) learning rate in optimizer.\n    Proposed in 'Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour'.\n    Args:\n        optimizer (Optimizer): Wrapped optimizer.\n        multiplier: target learning rate = base lr * multiplier if multiplier > 1.0. if multiplier = 1.0, lr starts from 0 and ends up with the base_lr.\n        total_epoch: target learning rate is reached at total_epoch, gradually\n        after_scheduler: after target_epoch, use this scheduler(eg. ReduceLROnPlateau)\n    \"\"\"\n\n    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n        self.multiplier = multiplier\n        if self.multiplier < 1.:\n            raise ValueError('multiplier should be greater thant or equal to 1.')\n        self.total_epoch = total_epoch\n        self.after_scheduler = after_scheduler\n        self.finished = False\n        super(GradualWarmupScheduler, self).__init__(optimizer)\n\n    def get_lr(self):\n        if self.last_epoch > self.total_epoch:\n            if self.after_scheduler:\n                if not self.finished:\n                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n                    self.finished = True\n                return self.after_scheduler.get_last_lr()\n            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n\n        if self.multiplier == 1.0:\n            return [base_lr * self.last_epoch / self.total_epoch for base_lr in self.base_lrs]\n        else:\n            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n\n    def step_ReduceLROnPlateau(self, metrics, epoch=None):\n        if epoch is None:\n            epoch = self.last_epoch + 1\n        self.last_epoch = epoch if epoch != 0 else 1  # ReduceLROnPlateau is called at the end of epoch, whereas others are called at beginning\n        if self.last_epoch <= self.total_epoch:\n            warmup_lr = [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n            for param_group, lr in zip(self.optimizer.param_groups, warmup_lr):\n                param_group['lr'] = lr\n        else:\n            if epoch is None:\n                self.after_scheduler.step(metrics, None)\n            else:\n                self.after_scheduler.step(metrics, epoch - self.total_epoch)\n\n    def step(self, epoch=None, metrics=None):\n        if type(self.after_scheduler) != ReduceLROnPlateau:\n            if self.finished and self.after_scheduler:\n                if epoch is None:\n                    self.after_scheduler.step(None)\n                else:\n                    self.after_scheduler.step(epoch - self.total_epoch)\n                self._last_lr = self.after_scheduler.get_last_lr()\n            else:\n                return super(GradualWarmupScheduler, self).step(epoch)\n        else:\n            if self.finished:\n                if epoch is None:\n                    self.after_scheduler.step(metrics, None)\n                else:\n                    self.after_scheduler.step(metrics, epoch - self.total_epoch)\n            else:\n                return super(GradualWarmupScheduler, self).step(epoch)\n\ndef get_scheduler(cfg, optimizers):\n    schedulers = []\n    for optimizer in optimizers:\n        scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(\n            optimizer, cfg.epochs, eta_min=1e-7)\n        scheduler = GradualWarmupScheduler(\n            optimizer, multiplier=10, total_epoch=1, after_scheduler=scheduler_cosine)\n        schedulers.append(scheduler)\n\n    return schedulers\n\n\ndef scheduler_step(scheduler, avg_val_loss, epoch):\n    scheduler.step(epoch)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## main","metadata":{}},{"cell_type":"code","source":"model = build_ensemble_model()\nschedulers = get_scheduler(CFG, model.optimizers)\n\nDiceLoss = smp.losses.DiceLoss(mode='binary')\nBCELoss = smp.losses.SoftBCEWithLogitsLoss()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alpha = 0.5\nbeta = 1 - alpha\nTverskyLoss = smp.losses.TverskyLoss(\n    mode='binary', log_loss=False, alpha=alpha, beta=beta)\n\ndef criterion(y_pred, y_true):\n    # return 0.5 * BCELoss(y_pred, y_true) + 0.5 * DiceLoss(y_pred, y_true)\n    return BCELoss(y_pred, y_true)\n    # return 0.5 * BCELoss(y_pred, y_true) + 0.5 * TverskyLoss(y_pred, y_true)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = []\nfor fragment_id in fragment_ids:\n    \n    # 1. Run inference on the test set and generate the pseudo labels\n    test_loader, xyxys = make_test_dataset(fragment_id)\n    pseudo_labels = run_inference(model, test_loader)\n        \n    # 1.1. Load test images\n    test_images = read_image(fragment_id, mode='test')  # Replace 'test' with the correct mode if needed\n\n    # 2. Create a dataset using the test images and their pseudo labels\n    test_images_list = [test_images[y1:y2, x1:x2] for y1, x1, y2, x2 in xyxys]\n    pseudo_labeled_dataset = CustomDataset(test_images_list, CFG, labels=pseudo_labels, transform=get_transforms(data='train', cfg=CFG), pseudo_label=True)\n\n    # 3. Train the model further using the pseudo-labeled dataset\n    train_loader = DataLoader(pseudo_labeled_dataset, batch_size=CFG.batch_size, shuffle=True, num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(pseudo_labeled_dataset, batch_size=CFG.valid_batch_size, shuffle=False, num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n\n    for epoch in range(CFG.epochs):\n        train_loss = train_fn(train_loader, model, criterion, optimizer, device)\n        valid_loss, mask_pred = valid_fn(valid_loader, model, criterion, device, xyxys, binary_mask)\n        # Update your model checkpoint or learning rate scheduler as needed\n    \n    # 4. Run inference on the test set again with the updated model and store the results\n    mask_pred = run_inference(model, test_loader)\n    mask_pred = postprocess_mask(mask_pred)  # You need to implement the postprocess_mask function to threshold and resize the mask\n    \n    inklabels_rle = rle(mask_pred)\n    results.append((fragment_id, inklabels_rle))\n\n    del mask_pred, mask_count\n    del test_loader\n    \n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T04:52:01.417925Z","iopub.execute_input":"2023-04-04T04:52:01.418536Z","iopub.status.idle":"2023-04-04T05:04:59.789188Z","shell.execute_reply.started":"2023-04-04T04:52:01.418493Z","shell.execute_reply":"2023-04-04T05:04:59.788009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## submission","metadata":{}},{"cell_type":"code","source":"sub = pd.DataFrame(results, columns=['Id', 'Predicted'])","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:04:59.791024Z","iopub.execute_input":"2023-04-04T05:04:59.79253Z","iopub.status.idle":"2023-04-04T05:04:59.80219Z","shell.execute_reply.started":"2023-04-04T05:04:59.792484Z","shell.execute_reply":"2023-04-04T05:04:59.801265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:04:59.803914Z","iopub.execute_input":"2023-04-04T05:04:59.804364Z","iopub.status.idle":"2023-04-04T05:04:59.832688Z","shell.execute_reply.started":"2023-04-04T05:04:59.804326Z","shell.execute_reply":"2023-04-04T05:04:59.831168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub = pd.read_csv(CFG.comp_dataset_path + 'sample_submission.csv')\nsample_sub = pd.merge(sample_sub[['Id']], sub, on='Id', how='left')","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:04:59.833854Z","iopub.execute_input":"2023-04-04T05:04:59.834119Z","iopub.status.idle":"2023-04-04T05:04:59.862057Z","shell.execute_reply.started":"2023-04-04T05:04:59.834093Z","shell.execute_reply":"2023-04-04T05:04:59.861126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:04:59.863677Z","iopub.execute_input":"2023-04-04T05:04:59.864045Z","iopub.status.idle":"2023-04-04T05:04:59.874408Z","shell.execute_reply.started":"2023-04-04T05:04:59.864009Z","shell.execute_reply":"2023-04-04T05:04:59.873278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T05:04:59.875995Z","iopub.execute_input":"2023-04-04T05:04:59.876637Z","iopub.status.idle":"2023-04-04T05:04:59.890511Z","shell.execute_reply.started":"2023-04-04T05:04:59.8766Z","shell.execute_reply":"2023-04-04T05:04:59.88919Z"},"trusted":true},"execution_count":null,"outputs":[]}]}